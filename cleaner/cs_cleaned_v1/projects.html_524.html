<p><span>The National Science Foundation<br> Rochester Institute of Technology</span></p> Research Experiences for Undergraduates in Computational Sensing        
<ul> 
 <li><a rel="nofollow">home</a></li> 
 <li><a rel="nofollow">research mentors</a></li> 
 <li><a rel="nofollow">participants</a></li> 
 <li><a rel="nofollow">workshop facilitators</a></li> 
 <li><a rel="nofollow">projects</a></li> 
 <li><a rel="nofollow">faq</a></li> 
 <li><a rel="nofollow">activities</a></li> 
</ul>     Projects  
<a rel="nofollow">  </a> 
<a rel="nofollow">  </a>    Project 1: Real-time attention, stress, and cognitive load monitoring 
<p> In recent work, we used a microphone to record speech and a camera to capture facial expressions of individuals engaged in computer-based tasks. The nature of the tasks were manipulated to induce moderate stress. We were later able to fuse both sources of data to reliably predict when the user was stressed. Students involved in this project will build on these ideas and develop techniques for real-time monitoring of user stress, attention, and cognitive load from multisource data towards monitoring in online learning systems. </p> 
<p><em>Faculty mentors:</em> Drs. Joe Geigel, Rennie Bailey, Linwei Wang, Cecilia Ovesdotter Alm.</p>   Project 2: Macro-level understanding of interpersonal violence 
<p>Interpersonal violence (IPV) and abuse are prominent problems that impact individuals and macro-level community wellness. Our findings from large social media collections include that beliefs, values, social pressure, and fears play major roles in keeping people in abusive relationships. Semantic role labeling is a method that can help identify information. Our prior work also showed that such tools are not well tailored to this data. Students will focus on: (1) inventorying and modifying prior semantic role labeling tools to better extract information on IPV from social media data, and (2) identifying quantifiable relations between signals in social media narratives, geospatial information, and demographic data sources.</p> 
<p><em>Faculty mentors:</em> Drs. Chris Homan, Ray Ptucha, Cecilia Ovesdotter Alm.</p>     Project 3: Multimodal interface with adaptive user feedback 
<p>We will extend techniques to systematically fuse multimodal data, representing experts’ domain knowledge, to improve image understanding. Students will enhance a prototype multimodal interactive user interface with interactive machine learning, to effectively collect and incorporate user feedback to enhance the data fusion results.</p> 
<p><em>Faculty mentors:</em> Drs. Qi Yu and Anne Haake.</p>   Project 4: Computational sensing in virtual locations 
<p>Post-apocalyptic storytelling in computer games tends to heavily rely on conveying–and users experiencing–haptic, visual and aural cues of danger. Students will study how creative narrative and computational design capture, convey, and produce sensory experience. Students will participate in developing and implementing a game prototype of a post-apocalyptic version of Rochester, the city they are in, and study creative reactions in users.</p> 
<p><em>Faculty mentors:</em> Drs. Sandy Baldwin and Trent Hergenrader.</p>     Project 5: Visual-linguistic alignment and beyond 
<p>In statistical machine translation, bitext word alignment is the first step in translating text from one language to another. Alignment algorithms can establish meaningful relationships between observers’ gaze data and their co-collected verbal image descriptions, for image annotation or classification. REU student researchers will (1) extend the bi-modality alignment framework to new modalities, (2) automate transcription with speech recognition, and (3) explore alignment quality considering factors such as concept concreteness and specificity, image domain, and observer background knowledge</p> 
<p><em>Faculty mentors:</em> Drs. Emily Prud’hommeaux, Cecilia Ovesdotter Alm, and Reynold Bailey.</p>        Computational Sensing REU (2016-2018)  Rochester Institute of Technology
<br> 
<span>Primary contact:</span> Cecilia Ovesdotter Alm, coagla@rit.edu, (585) 475-7327
<br> 
<span>Secondary contact:</span> Reynold Bailey, rjb@cs.rit.edu, (585) 475-6181    
<p><em>This material is based upon work supported by the National Science Foundation under Award No. IIS‐1559889.</em><br> <em>Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.</em></p>